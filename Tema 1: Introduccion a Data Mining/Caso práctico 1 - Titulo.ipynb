{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor:  \n",
    "Manuel Eugenio Morocho Cayamcela, PhD\n",
    "\n",
    "# **Caso práctico 1:** \n",
    "## Procesamiento y Transformación de Datos para Análisis de Crédito\n",
    "\n",
    "Este tutorial cubrirá tres fases clave en el procesamiento y transformación de datos para el análisis de crédito: limpieza de datos, transformación de datos y selección de características. Utilizaremos un conjunto de datos de solicitudes de crédito para este tutorial.\n",
    "\n",
    "### **Fase I:** Limpieza de Datos\n",
    "\n",
    "#### Carga de Datos\n",
    "\n",
    "Primero, necesitamos cargar nuestro conjunto de datos. Supongamos que nuestros datos están en un archivo CSV llamado 'credit_data.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('credit_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Exploración de Tipos de Datos\n",
    "\n",
    "Para entender qué tipo de datos tenemos, podemos usar el método `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identificación y Manejo de Valores Faltantes\n",
    "\n",
    "Los valores faltantes pueden ser identificados con el método `isnull()`. Para manejarlos, podemos usar la imputación (rellenar los valores faltantes con la media, mediana, o moda) o simplemente eliminar las filas con valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar valores faltantes\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Imputar valores faltantes con la media\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Identificación y Manejo de Outliers\n",
    "\n",
    "Los outliers pueden ser identificados utilizando métodos estadísticos, como el método del rango intercuartil (IQR). Una vez identificados, pueden ser eliminados o ajustados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar outliers con el método IQR\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Eliminar outliers\n",
    "data = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identificación y Manejo de Datos Inconsistentes\n",
    "\n",
    "Los datos inconsistentes pueden ser identificados revisando los valores únicos de cada característica. Una vez identificados, pueden ser corregidos o eliminados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar datos inconsistentes\n",
    "for column in data.columns:\n",
    "    print(data[column].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanceo de Datos\n",
    "\n",
    "El balanceo de datos puede ser necesario si nuestra variable objetivo está desbalanceada. Podemos usar técnicas como el oversampling o el undersampling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(data.drop('target', axis=1), data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Fase II:** Transformación de Datos\n",
    "\n",
    "#### 1. Normalización\n",
    "\n",
    "La normalización ajusta los valores en un rango común.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Discretización\n",
    "\n",
    "La discretización convierte las variables continuas en variables discretas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = pd.cut(data['age'], bins=3, labels=['young', 'middle-aged', 'old'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Codificación de Variables\n",
    "\n",
    "La codificación de variables convierte las variables categóricas en variables numéricas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Fase III:** Selección de Características\n",
    "\n",
    "La selección de características identifica las variables más relevantes para nuestro análisis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit_transform(data_encoded, data_encoded['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Finalmente, podemos usar una regresión lineal (o cualquier otro modelo de aprendizaje automático) para predecir si a un cliente se le otorgará crédito o no.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este tutorial es solo una introducción a las técnicas de procesamiento y transformación de datos. Hay muchas otras técnicas y métodos disponibles, y la elección de las técnicas a utilizar dependerá de la naturaleza de tus datos y del problema que estés tratando de resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resolución:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
